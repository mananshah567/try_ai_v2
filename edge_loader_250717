import time
from gremlin_python.driver.client import Client
from gremlin_python.driver.protocol import GremlinServerError
from ipywidgets import IntProgress, HTML, VBox
from IPython.display import display

def load_existing_edges(
    client: Client,
    throttler,
    batch_size: int = 1000,
    minimal_batch: int = 100,
    max_retries: int = 3,
    backoff_base: float = 1.0
) -> set:
    """
    Robustly load all existing edge IDs via continuation tokens, with dynamic batch resizing
    on timeouts, retry/backoff on rate limits, RU throttling, and a notebook progress bar.
    Returns a set of edge IDs.
    """
    continuation = None
    inserted_edge_ids = set()

    # Attempt to get total count for sizing the progress bar
    try:
        total = client.submit(
            "g.E().count()", {}, request_options={"pageSize": 1}
        ).all().result()[0]
        bar = IntProgress(min=0, max=total, description="Edges:")
    except Exception as e:
        print(f"Could not retrieve edge count: {e}")
        total = None
        bar = IntProgress(min=0, description="Edges:")
    label = HTML()
    display(VBox([label, bar]))

    start = time.time()
    loaded = 0
    label.value = f"Loaded 0{'/' + str(total) if total else ''} edges..."
    current_batch = batch_size

    while True:
        # Fetch one page of IDs, with retry/backoff & dynamic batch sizing
        attempts = 0
        while True:
            try:
                rs = client.submit(
                    "g.E().id()",
                    {},
                    request_options={"continuation": continuation, "pageSize": current_batch}
                )
                ids = rs.all().result()
                ru = float(rs.status_attributes.get("x-ms-total-request-charge", 10.0))
                throttler.throttle(ru)
                break
            except GremlinServerError as e:
                msg = str(e)
                print(f"Fetch attempt {attempts+1} failed: {msg}")
                if "429" in msg or "GraphTimeoutException" in msg:
                    attempts += 1
                    if attempts >= max_retries:
                        # If we’re already at the minimal batch, abort
                        if current_batch <= minimal_batch:
                            print("⚠️ Fetch aborted: minimal batch size reached.")
                            return inserted_edge_ids
                        # Otherwise, halve the batch and retry from scratch
                        current_batch = max(minimal_batch, current_batch // 2)
                        print(f"⚡ Reducing batch_size to {current_batch} and retrying...")
                        attempts = 0
                        time.sleep(backoff_base)
                        continue
                    # Exponential backoff before next retry
                    time.sleep(backoff_base * (2 ** (attempts - 1)))
                    continue
                else:
                    raise

        if not ids:
            # No more edges
            break

        # Collect and update progress
        for eid in ids:
            inserted_edge_ids.add(eid)
        loaded += len(ids)
        bar.value = loaded
        elapsed = time.time() - start
        rate = loaded / elapsed if elapsed else 0
        eta = (total - loaded) / rate if (total and rate) else float("inf")
        label.value = f"Loaded {loaded}{'/' + str(total) if total else ''} · ETA {eta:.1f}s"

        continuation = rs.status_attributes.get("x-ms-continuation")
        if not continuation:
            break

    return inserted_edge_ids
